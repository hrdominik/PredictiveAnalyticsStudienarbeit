{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "from sklearn.feature_extraction.text import CountVectorizer\r\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
    "from sklearn.pipeline import Pipeline\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "source": [
    "# df = pd.read_csv('../data/analyst_ratings_processed_final.csv')[['headline', 'stock', 'headline_cleaned']]\r\n",
    "df = pd.read_csv('../data/analyst_ratings_processed_final.csv')\r\n",
    "# df = df.sample(5000)\r\n",
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   id                                           headline  \\\n",
       "0   0            Stocks That Hit 52-Week Highs On Friday   \n",
       "1   1         Stocks That Hit 52-Week Highs On Wednesday   \n",
       "2   2                      71 Biggest Movers From Friday   \n",
       "3   3       46 Stocks Moving In Friday's Mid-Day Session   \n",
       "4   4  B of A Securities Maintains Neutral on Agilent...   \n",
       "\n",
       "                                                 url          publisher  \\\n",
       "0  https://www.benzinga.com/news/20/06/16190091/s...  Benzinga Insights   \n",
       "1  https://www.benzinga.com/news/20/06/16170189/s...  Benzinga Insights   \n",
       "2  https://www.benzinga.com/news/20/05/16103463/7...         Lisa Levin   \n",
       "3  https://www.benzinga.com/news/20/05/16095921/4...         Lisa Levin   \n",
       "4  https://www.benzinga.com/news/20/05/16095304/b...         Vick Meyer   \n",
       "\n",
       "         date stock                                   headline_cleaned  \\\n",
       "0  2020-06-05     A  ['stock.n.01', 'hit.v.01', 'high.n.01', 'frida...   \n",
       "1  2020-06-03     A  ['stock.n.01', 'hit.v.01', 'high.n.01', 'wedne...   \n",
       "2  2020-05-26     A        ['large.a.01', 'mover.n.01', 'friday.n.01']   \n",
       "3  2020-05-22     A  ['stock.n.01', 'travel.v.01', 'friday.n.01', '...   \n",
       "4  2020-05-22     A  ['security.n.01', 'neutral.n.01', 'technology....   \n",
       "\n",
       "   senti_pos_score  senti_neg_score  senti_score   open  close  \n",
       "0            0.125            0.000        0.125  92.13  90.38  \n",
       "1            0.125            0.000        0.125  90.65  90.49  \n",
       "2            0.250            0.125        0.125  86.23  86.13  \n",
       "3            0.000            0.000        0.000  85.00  84.98  \n",
       "4            0.500            0.250        0.250  85.00  84.98  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>headline</th>\n",
       "      <th>url</th>\n",
       "      <th>publisher</th>\n",
       "      <th>date</th>\n",
       "      <th>stock</th>\n",
       "      <th>headline_cleaned</th>\n",
       "      <th>senti_pos_score</th>\n",
       "      <th>senti_neg_score</th>\n",
       "      <th>senti_score</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Stocks That Hit 52-Week Highs On Friday</td>\n",
       "      <td>https://www.benzinga.com/news/20/06/16190091/s...</td>\n",
       "      <td>Benzinga Insights</td>\n",
       "      <td>2020-06-05</td>\n",
       "      <td>A</td>\n",
       "      <td>['stock.n.01', 'hit.v.01', 'high.n.01', 'frida...</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>92.13</td>\n",
       "      <td>90.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Stocks That Hit 52-Week Highs On Wednesday</td>\n",
       "      <td>https://www.benzinga.com/news/20/06/16170189/s...</td>\n",
       "      <td>Benzinga Insights</td>\n",
       "      <td>2020-06-03</td>\n",
       "      <td>A</td>\n",
       "      <td>['stock.n.01', 'hit.v.01', 'high.n.01', 'wedne...</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>90.65</td>\n",
       "      <td>90.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>71 Biggest Movers From Friday</td>\n",
       "      <td>https://www.benzinga.com/news/20/05/16103463/7...</td>\n",
       "      <td>Lisa Levin</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>A</td>\n",
       "      <td>['large.a.01', 'mover.n.01', 'friday.n.01']</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "      <td>86.23</td>\n",
       "      <td>86.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>46 Stocks Moving In Friday's Mid-Day Session</td>\n",
       "      <td>https://www.benzinga.com/news/20/05/16095921/4...</td>\n",
       "      <td>Lisa Levin</td>\n",
       "      <td>2020-05-22</td>\n",
       "      <td>A</td>\n",
       "      <td>['stock.n.01', 'travel.v.01', 'friday.n.01', '...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>85.00</td>\n",
       "      <td>84.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>B of A Securities Maintains Neutral on Agilent...</td>\n",
       "      <td>https://www.benzinga.com/news/20/05/16095304/b...</td>\n",
       "      <td>Vick Meyer</td>\n",
       "      <td>2020-05-22</td>\n",
       "      <td>A</td>\n",
       "      <td>['security.n.01', 'neutral.n.01', 'technology....</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.250</td>\n",
       "      <td>85.00</td>\n",
       "      <td>84.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 131
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "source": [
    "def stockDevelopement(row):\r\n",
    "    stock_differenz = row['open'] - row['close']\r\n",
    "    return 1 - row['close']/row['open']\r\n",
    "    # if quotient < 1:\r\n",
    "    #     return -1\r\n",
    "    # elif quotient > 1:\r\n",
    "    #     return 1\r\n",
    "    # else: return 0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "source": [
    "df['stockPriceChange'] = df.apply(stockDevelopement, axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "source": [
    "df = df[['id','headline', 'stock', 'headline_cleaned','open','close', \"stockPriceChange\"]]\r\n",
    "df = df.rename(columns={'headline': '_headline', 'headline_cleaned':'_headline_cleaned', 'stock': '_stock', 'open': '_open', 'close':'_close', 'stockPrice_Change':'_stockPrice_Change'})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "source": [
    "def tokenz_in_sentence(hl):\r\n",
    "    word_list = hl[1:-1].split(\", \")\r\n",
    "    word_list = [word[1:-6] for word in word_list]\r\n",
    "    sentence = ' '.join(word_list)\r\n",
    "    return sentence"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "source": [
    "df['_headline_sentence'] = df._headline_cleaned.apply(tokenz_in_sentence)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "source": [
    "df = df.set_index('id')\r\n",
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                            _headline _stock  \\\n",
       "id                                                             \n",
       "0             Stocks That Hit 52-Week Highs On Friday      A   \n",
       "1          Stocks That Hit 52-Week Highs On Wednesday      A   \n",
       "2                       71 Biggest Movers From Friday      A   \n",
       "3        46 Stocks Moving In Friday's Mid-Day Session      A   \n",
       "4   B of A Securities Maintains Neutral on Agilent...      A   \n",
       "\n",
       "                                    _headline_cleaned  _open  _close  \\\n",
       "id                                                                     \n",
       "0   ['stock.n.01', 'hit.v.01', 'high.n.01', 'frida...  92.13   90.38   \n",
       "1   ['stock.n.01', 'hit.v.01', 'high.n.01', 'wedne...  90.65   90.49   \n",
       "2         ['large.a.01', 'mover.n.01', 'friday.n.01']  86.23   86.13   \n",
       "3   ['stock.n.01', 'travel.v.01', 'friday.n.01', '...  85.00   84.98   \n",
       "4   ['security.n.01', 'neutral.n.01', 'technology....  85.00   84.98   \n",
       "\n",
       "    stockPriceChange                                 _headline_sentence  \n",
       "id                                                                       \n",
       "0           0.018995                              stock hit high friday  \n",
       "1           0.001765                           stock hit high wednesday  \n",
       "2           0.001160                                 large mover friday  \n",
       "3           0.000235                        stock travel friday session  \n",
       "4           0.000235  security neutral technology raise monetary_val...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_headline</th>\n",
       "      <th>_stock</th>\n",
       "      <th>_headline_cleaned</th>\n",
       "      <th>_open</th>\n",
       "      <th>_close</th>\n",
       "      <th>stockPriceChange</th>\n",
       "      <th>_headline_sentence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stocks That Hit 52-Week Highs On Friday</td>\n",
       "      <td>A</td>\n",
       "      <td>['stock.n.01', 'hit.v.01', 'high.n.01', 'frida...</td>\n",
       "      <td>92.13</td>\n",
       "      <td>90.38</td>\n",
       "      <td>0.018995</td>\n",
       "      <td>stock hit high friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stocks That Hit 52-Week Highs On Wednesday</td>\n",
       "      <td>A</td>\n",
       "      <td>['stock.n.01', 'hit.v.01', 'high.n.01', 'wedne...</td>\n",
       "      <td>90.65</td>\n",
       "      <td>90.49</td>\n",
       "      <td>0.001765</td>\n",
       "      <td>stock hit high wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>71 Biggest Movers From Friday</td>\n",
       "      <td>A</td>\n",
       "      <td>['large.a.01', 'mover.n.01', 'friday.n.01']</td>\n",
       "      <td>86.23</td>\n",
       "      <td>86.13</td>\n",
       "      <td>0.001160</td>\n",
       "      <td>large mover friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46 Stocks Moving In Friday's Mid-Day Session</td>\n",
       "      <td>A</td>\n",
       "      <td>['stock.n.01', 'travel.v.01', 'friday.n.01', '...</td>\n",
       "      <td>85.00</td>\n",
       "      <td>84.98</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>stock travel friday session</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B of A Securities Maintains Neutral on Agilent...</td>\n",
       "      <td>A</td>\n",
       "      <td>['security.n.01', 'neutral.n.01', 'technology....</td>\n",
       "      <td>85.00</td>\n",
       "      <td>84.98</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>security neutral technology raise monetary_val...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 137
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "source": [
    "df['stockPriceChange'] = df['stockPriceChange'].apply(lambda value: value*100)\r\n",
    "df['stockPriceChange'] = df['stockPriceChange'].astype(np.float16)\r\n",
    "df['_open'] = df['_open'].astype(np.float16)\r\n",
    "df['_close'] = df['_close'].astype(np.float16)\r\n",
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                            _headline _stock  \\\n",
       "id                                                             \n",
       "0             Stocks That Hit 52-Week Highs On Friday      A   \n",
       "1          Stocks That Hit 52-Week Highs On Wednesday      A   \n",
       "2                       71 Biggest Movers From Friday      A   \n",
       "3        46 Stocks Moving In Friday's Mid-Day Session      A   \n",
       "4   B of A Securities Maintains Neutral on Agilent...      A   \n",
       "\n",
       "                                    _headline_cleaned   _open  _close  \\\n",
       "id                                                                      \n",
       "0   ['stock.n.01', 'hit.v.01', 'high.n.01', 'frida...  92.125  90.375   \n",
       "1   ['stock.n.01', 'hit.v.01', 'high.n.01', 'wedne...  90.625  90.500   \n",
       "2         ['large.a.01', 'mover.n.01', 'friday.n.01']  86.250  86.125   \n",
       "3   ['stock.n.01', 'travel.v.01', 'friday.n.01', '...  85.000  85.000   \n",
       "4   ['security.n.01', 'neutral.n.01', 'technology....  85.000  85.000   \n",
       "\n",
       "    stockPriceChange                                 _headline_sentence  \n",
       "id                                                                       \n",
       "0           1.899414                              stock hit high friday  \n",
       "1           0.176514                           stock hit high wednesday  \n",
       "2           0.115967                                 large mover friday  \n",
       "3           0.023529                        stock travel friday session  \n",
       "4           0.023529  security neutral technology raise monetary_val...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_headline</th>\n",
       "      <th>_stock</th>\n",
       "      <th>_headline_cleaned</th>\n",
       "      <th>_open</th>\n",
       "      <th>_close</th>\n",
       "      <th>stockPriceChange</th>\n",
       "      <th>_headline_sentence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stocks That Hit 52-Week Highs On Friday</td>\n",
       "      <td>A</td>\n",
       "      <td>['stock.n.01', 'hit.v.01', 'high.n.01', 'frida...</td>\n",
       "      <td>92.125</td>\n",
       "      <td>90.375</td>\n",
       "      <td>1.899414</td>\n",
       "      <td>stock hit high friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stocks That Hit 52-Week Highs On Wednesday</td>\n",
       "      <td>A</td>\n",
       "      <td>['stock.n.01', 'hit.v.01', 'high.n.01', 'wedne...</td>\n",
       "      <td>90.625</td>\n",
       "      <td>90.500</td>\n",
       "      <td>0.176514</td>\n",
       "      <td>stock hit high wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>71 Biggest Movers From Friday</td>\n",
       "      <td>A</td>\n",
       "      <td>['large.a.01', 'mover.n.01', 'friday.n.01']</td>\n",
       "      <td>86.250</td>\n",
       "      <td>86.125</td>\n",
       "      <td>0.115967</td>\n",
       "      <td>large mover friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46 Stocks Moving In Friday's Mid-Day Session</td>\n",
       "      <td>A</td>\n",
       "      <td>['stock.n.01', 'travel.v.01', 'friday.n.01', '...</td>\n",
       "      <td>85.000</td>\n",
       "      <td>85.000</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>stock travel friday session</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B of A Securities Maintains Neutral on Agilent...</td>\n",
       "      <td>A</td>\n",
       "      <td>['security.n.01', 'neutral.n.01', 'technology....</td>\n",
       "      <td>85.000</td>\n",
       "      <td>85.000</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>security neutral technology raise monetary_val...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 138
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "source": [
    "df_set = df['_headline_sentence'].tolist()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "source": [
    "df.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(161478, 7)"
      ]
     },
     "metadata": {},
     "execution_count": 140
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "source": [
    "count_vectorizer = CountVectorizer(analyzer=\"word\", stop_words=\"english\")\r\n",
    "tfidf_vectorizer = TfidfVectorizer(analyzer='word', stop_words='english')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "source": [
    "count_wm = count_vectorizer.fit_transform(df_set)\r\n",
    "tfidf_wm = tfidf_vectorizer.fit_transform(df_set)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "source": [
    "count_tokenz = count_vectorizer.get_feature_names()\r\n",
    "tfidf_tokenz = tfidf_vectorizer.get_feature_names()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "source": [
    "df_countvect = pd.DataFrame(data=count_wm.toarray(), index=df.index, columns=count_tokenz)\r\n",
    "df_tfidfvect = pd.DataFrame(data= tfidf_wm.toarray(), index=df.index, columns=tfidf_tokenz)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "source": [
    "df_tfidfvect.head()\r\n",
    "# df_countvect.sample(50)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    131  aare  aaron  abacus  abandon  abattoir  abbot  abbreviated  \\\n",
       "id                                                                    \n",
       "0   0.0   0.0    0.0     0.0      0.0       0.0    0.0          0.0   \n",
       "1   0.0   0.0    0.0     0.0      0.0       0.0    0.0          0.0   \n",
       "2   0.0   0.0    0.0     0.0      0.0       0.0    0.0          0.0   \n",
       "3   0.0   0.0    0.0     0.0      0.0       0.0    0.0          0.0   \n",
       "4   0.0   0.0    0.0     0.0      0.0       0.0    0.0          0.0   \n",
       "\n",
       "    abdominal  abdominal_aortic_aneurysm  ...  zebra  zebu  zero  zeus  zhou  \\\n",
       "id                                        ...                                  \n",
       "0         0.0                        0.0  ...    0.0   0.0   0.0   0.0   0.0   \n",
       "1         0.0                        0.0  ...    0.0   0.0   0.0   0.0   0.0   \n",
       "2         0.0                        0.0  ...    0.0   0.0   0.0   0.0   0.0   \n",
       "3         0.0                        0.0  ...    0.0   0.0   0.0   0.0   0.0   \n",
       "4         0.0                        0.0  ...    0.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "    ziegler  zinc  zion  zip_up  zone  \n",
       "id                                     \n",
       "0       0.0   0.0   0.0     0.0   0.0  \n",
       "1       0.0   0.0   0.0     0.0   0.0  \n",
       "2       0.0   0.0   0.0     0.0   0.0  \n",
       "3       0.0   0.0   0.0     0.0   0.0  \n",
       "4       0.0   0.0   0.0     0.0   0.0  \n",
       "\n",
       "[5 rows x 8713 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>131</th>\n",
       "      <th>aare</th>\n",
       "      <th>aaron</th>\n",
       "      <th>abacus</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abattoir</th>\n",
       "      <th>abbot</th>\n",
       "      <th>abbreviated</th>\n",
       "      <th>abdominal</th>\n",
       "      <th>abdominal_aortic_aneurysm</th>\n",
       "      <th>...</th>\n",
       "      <th>zebra</th>\n",
       "      <th>zebu</th>\n",
       "      <th>zero</th>\n",
       "      <th>zeus</th>\n",
       "      <th>zhou</th>\n",
       "      <th>ziegler</th>\n",
       "      <th>zinc</th>\n",
       "      <th>zion</th>\n",
       "      <th>zip_up</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 8713 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 145
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "source": [
    "cols_to_delete = []\r\n",
    "for column in df_tfidfvect:\r\n",
    "    count = df_tfidfvect[df_tfidfvect[column] > 0].shape[0]\r\n",
    "    # print(df_tfidfvect[df_tfidfvect[column] > 0].shape[0])\r\n",
    "    if count<50 or count> 2000:\r\n",
    "        cols_to_delete.append(column)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "source": [
    "print(len(cols_to_delete))\r\n",
    "print(df_tfidfvect.shape[1])\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "7181\n",
      "8713\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "source": [
    "df_tfidfvect.drop(axis=1, columns=cols_to_delete, inplace=True)\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "source": [
    "df_tfidfvect.head()\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    aaron  ability  acadia  accelerate  ache  acme  acquisition  act  acting  \\\n",
       "id                                                                             \n",
       "0     0.0      0.0     0.0         0.0   0.0   0.0          0.0  0.0     0.0   \n",
       "1     0.0      0.0     0.0         0.0   0.0   0.0          0.0  0.0     0.0   \n",
       "2     0.0      0.0     0.0         0.0   0.0   0.0          0.0  0.0     0.0   \n",
       "3     0.0      0.0     0.0         0.0   0.0   0.0          0.0  0.0     0.0   \n",
       "4     0.0      0.0     0.0         0.0   0.0   0.0          0.0  0.0     0.0   \n",
       "\n",
       "    action  ...  worsen  worst  worth  wuhan  xerox  yak  year  yip  york  \\\n",
       "id          ...                                                             \n",
       "0      0.0  ...     0.0    0.0    0.0    0.0    0.0  0.0   0.0  0.0   0.0   \n",
       "1      0.0  ...     0.0    0.0    0.0    0.0    0.0  0.0   0.0  0.0   0.0   \n",
       "2      0.0  ...     0.0    0.0    0.0    0.0    0.0  0.0   0.0  0.0   0.0   \n",
       "3      0.0  ...     0.0    0.0    0.0    0.0    0.0  0.0   0.0  0.0   0.0   \n",
       "4      0.0  ...     0.0    0.0    0.0    0.0    0.0  0.0   0.0  0.0   0.0   \n",
       "\n",
       "    zion  \n",
       "id        \n",
       "0    0.0  \n",
       "1    0.0  \n",
       "2    0.0  \n",
       "3    0.0  \n",
       "4    0.0  \n",
       "\n",
       "[5 rows x 1532 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaron</th>\n",
       "      <th>ability</th>\n",
       "      <th>acadia</th>\n",
       "      <th>accelerate</th>\n",
       "      <th>ache</th>\n",
       "      <th>acme</th>\n",
       "      <th>acquisition</th>\n",
       "      <th>act</th>\n",
       "      <th>acting</th>\n",
       "      <th>action</th>\n",
       "      <th>...</th>\n",
       "      <th>worsen</th>\n",
       "      <th>worst</th>\n",
       "      <th>worth</th>\n",
       "      <th>wuhan</th>\n",
       "      <th>xerox</th>\n",
       "      <th>yak</th>\n",
       "      <th>year</th>\n",
       "      <th>yip</th>\n",
       "      <th>york</th>\n",
       "      <th>zion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1532 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 150
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "source": [
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                            _headline _stock  \\\n",
       "id                                                             \n",
       "0             Stocks That Hit 52-Week Highs On Friday      A   \n",
       "1          Stocks That Hit 52-Week Highs On Wednesday      A   \n",
       "2                       71 Biggest Movers From Friday      A   \n",
       "3        46 Stocks Moving In Friday's Mid-Day Session      A   \n",
       "4   B of A Securities Maintains Neutral on Agilent...      A   \n",
       "\n",
       "                                    _headline_cleaned   _open  _close  \\\n",
       "id                                                                      \n",
       "0   ['stock.n.01', 'hit.v.01', 'high.n.01', 'frida...  92.125  90.375   \n",
       "1   ['stock.n.01', 'hit.v.01', 'high.n.01', 'wedne...  90.625  90.500   \n",
       "2         ['large.a.01', 'mover.n.01', 'friday.n.01']  86.250  86.125   \n",
       "3   ['stock.n.01', 'travel.v.01', 'friday.n.01', '...  85.000  85.000   \n",
       "4   ['security.n.01', 'neutral.n.01', 'technology....  85.000  85.000   \n",
       "\n",
       "    stockPriceChange                                 _headline_sentence  \n",
       "id                                                                       \n",
       "0           1.899414                              stock hit high friday  \n",
       "1           0.176514                           stock hit high wednesday  \n",
       "2           0.115967                                 large mover friday  \n",
       "3           0.023529                        stock travel friday session  \n",
       "4           0.023529  security neutral technology raise monetary_val...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_headline</th>\n",
       "      <th>_stock</th>\n",
       "      <th>_headline_cleaned</th>\n",
       "      <th>_open</th>\n",
       "      <th>_close</th>\n",
       "      <th>stockPriceChange</th>\n",
       "      <th>_headline_sentence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stocks That Hit 52-Week Highs On Friday</td>\n",
       "      <td>A</td>\n",
       "      <td>['stock.n.01', 'hit.v.01', 'high.n.01', 'frida...</td>\n",
       "      <td>92.125</td>\n",
       "      <td>90.375</td>\n",
       "      <td>1.899414</td>\n",
       "      <td>stock hit high friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stocks That Hit 52-Week Highs On Wednesday</td>\n",
       "      <td>A</td>\n",
       "      <td>['stock.n.01', 'hit.v.01', 'high.n.01', 'wedne...</td>\n",
       "      <td>90.625</td>\n",
       "      <td>90.500</td>\n",
       "      <td>0.176514</td>\n",
       "      <td>stock hit high wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>71 Biggest Movers From Friday</td>\n",
       "      <td>A</td>\n",
       "      <td>['large.a.01', 'mover.n.01', 'friday.n.01']</td>\n",
       "      <td>86.250</td>\n",
       "      <td>86.125</td>\n",
       "      <td>0.115967</td>\n",
       "      <td>large mover friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46 Stocks Moving In Friday's Mid-Day Session</td>\n",
       "      <td>A</td>\n",
       "      <td>['stock.n.01', 'travel.v.01', 'friday.n.01', '...</td>\n",
       "      <td>85.000</td>\n",
       "      <td>85.000</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>stock travel friday session</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B of A Securities Maintains Neutral on Agilent...</td>\n",
       "      <td>A</td>\n",
       "      <td>['security.n.01', 'neutral.n.01', 'technology....</td>\n",
       "      <td>85.000</td>\n",
       "      <td>85.000</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>security neutral technology raise monetary_val...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 151
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "source": [
    "# merged_df = pd.concat([df.set_index('id'), df_tfidfvect.set_index('id')], axis=1, join='inner')\r\n",
    "mergred = df.merge(df_tfidfvect, on='id')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "source": [
    "mergred.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                _headline _stock  \\\n",
       "id                                                                 \n",
       "904477  Nektar Therapeutics shares are trading higher ...   NKTR   \n",
       "626331                      98 Biggest Movers From Friday     HP   \n",
       "292459         Stocks That Hit 52-Week Highs On Wednesday    CPT   \n",
       "963746  Benzinga's Top Upgrades, Downgrades For April ...   ORLY   \n",
       "211239  Mid-Morning Market Update: Markets Open Lower;...   CANF   \n",
       "\n",
       "                                        _headline_cleaned       _open  \\\n",
       "id                                                                      \n",
       "904477  ['remedy.n.02', 'share.n.01', 'trade.v.01', 'h...   20.406250   \n",
       "626331        ['large.a.01', 'mover.n.01', 'friday.n.01']   16.484375   \n",
       "292459  ['stock.n.01', 'hit.v.01', 'high.n.01', 'wedne...  113.375000   \n",
       "963746  ['top.n.01', 'ascent.n.01', 'downgrade.n.01', ...  368.250000   \n",
       "211239  ['market.n.01', 'update.n.01', 'market.n.01', ...    2.900391   \n",
       "\n",
       "            _close  stockPriceChange  \\\n",
       "id                                     \n",
       "904477   20.765625         -1.763672   \n",
       "626331   18.046875         -9.460938   \n",
       "292459  113.125000          0.220459   \n",
       "963746  358.250000          2.734375   \n",
       "211239    2.943359         -1.527344   \n",
       "\n",
       "                                       _headline_sentence  acadia  ache  \\\n",
       "id                                                                        \n",
       "904477  remedy share trade high company report sale co...     0.0   0.0   \n",
       "626331                                 large mover friday     0.0   0.0   \n",
       "292459                           stock hit high wednesday     0.0   0.0   \n",
       "963746                         top ascent downgrade april     0.0   0.0   \n",
       "211239  market update market open lower_berth supply p...     0.0   0.0   \n",
       "\n",
       "        acquisition  ...  western  white  widen  win  work  worker  worsen  \\\n",
       "id                   ...                                                     \n",
       "904477          0.0  ...      0.0    0.0    0.0  0.0   0.0     0.0     0.0   \n",
       "626331          0.0  ...      0.0    0.0    0.0  0.0   0.0     0.0     0.0   \n",
       "292459          0.0  ...      0.0    0.0    0.0  0.0   0.0     0.0     0.0   \n",
       "963746          0.0  ...      0.0    0.0    0.0  0.0   0.0     0.0     0.0   \n",
       "211239          0.0  ...      0.0    0.0    0.0  0.0   0.0     0.0     0.0   \n",
       "\n",
       "        wuhan  xerox  york  \n",
       "id                          \n",
       "904477    0.0    0.0   0.0  \n",
       "626331    0.0    0.0   0.0  \n",
       "292459    0.0    0.0   0.0  \n",
       "963746    0.0    0.0   0.0  \n",
       "211239    0.0    0.0   0.0  \n",
       "\n",
       "[5 rows x 588 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_headline</th>\n",
       "      <th>_stock</th>\n",
       "      <th>_headline_cleaned</th>\n",
       "      <th>_open</th>\n",
       "      <th>_close</th>\n",
       "      <th>stockPriceChange</th>\n",
       "      <th>_headline_sentence</th>\n",
       "      <th>acadia</th>\n",
       "      <th>ache</th>\n",
       "      <th>acquisition</th>\n",
       "      <th>...</th>\n",
       "      <th>western</th>\n",
       "      <th>white</th>\n",
       "      <th>widen</th>\n",
       "      <th>win</th>\n",
       "      <th>work</th>\n",
       "      <th>worker</th>\n",
       "      <th>worsen</th>\n",
       "      <th>wuhan</th>\n",
       "      <th>xerox</th>\n",
       "      <th>york</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>904477</th>\n",
       "      <td>Nektar Therapeutics shares are trading higher ...</td>\n",
       "      <td>NKTR</td>\n",
       "      <td>['remedy.n.02', 'share.n.01', 'trade.v.01', 'h...</td>\n",
       "      <td>20.406250</td>\n",
       "      <td>20.765625</td>\n",
       "      <td>-1.763672</td>\n",
       "      <td>remedy share trade high company report sale co...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626331</th>\n",
       "      <td>98 Biggest Movers From Friday</td>\n",
       "      <td>HP</td>\n",
       "      <td>['large.a.01', 'mover.n.01', 'friday.n.01']</td>\n",
       "      <td>16.484375</td>\n",
       "      <td>18.046875</td>\n",
       "      <td>-9.460938</td>\n",
       "      <td>large mover friday</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292459</th>\n",
       "      <td>Stocks That Hit 52-Week Highs On Wednesday</td>\n",
       "      <td>CPT</td>\n",
       "      <td>['stock.n.01', 'hit.v.01', 'high.n.01', 'wedne...</td>\n",
       "      <td>113.375000</td>\n",
       "      <td>113.125000</td>\n",
       "      <td>0.220459</td>\n",
       "      <td>stock hit high wednesday</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963746</th>\n",
       "      <td>Benzinga's Top Upgrades, Downgrades For April ...</td>\n",
       "      <td>ORLY</td>\n",
       "      <td>['top.n.01', 'ascent.n.01', 'downgrade.n.01', ...</td>\n",
       "      <td>368.250000</td>\n",
       "      <td>358.250000</td>\n",
       "      <td>2.734375</td>\n",
       "      <td>top ascent downgrade april</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211239</th>\n",
       "      <td>Mid-Morning Market Update: Markets Open Lower;...</td>\n",
       "      <td>CANF</td>\n",
       "      <td>['market.n.01', 'update.n.01', 'market.n.01', ...</td>\n",
       "      <td>2.900391</td>\n",
       "      <td>2.943359</td>\n",
       "      <td>-1.527344</td>\n",
       "      <td>market update market open lower_berth supply p...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 588 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 115
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "source": [
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\r\n",
    "\r\n",
    "# Number of trees in random forest\r\n",
    "n_estimators = [int(x) for x in np.linspace(start = 30, stop = 100, num = 10)]\r\n",
    "# Number of features to consider at every split\r\n",
    "max_features = ['auto', 'sqrt']\r\n",
    "# Maximum number of levels in tree\r\n",
    "max_depth = [int(x) for x in np.linspace(10, 50, num = 5)]\r\n",
    "max_depth.append(None)\r\n",
    "# Minimum number of samples required to split a node\r\n",
    "min_samples_split = [2, 3]\r\n",
    "# Minimum number of samples required at each leaf node\r\n",
    "min_samples_leaf = [1, 2]\r\n",
    "# Method of selecting samples for training each tree\r\n",
    "bootstrap = [True, False]\r\n",
    "# Create the random grid\r\n",
    "random_grid = {'n_estimators': n_estimators,\r\n",
    "               'max_features': max_features,\r\n",
    "               'max_depth': max_depth,\r\n",
    "               'min_samples_split': min_samples_split,\r\n",
    "               'min_samples_leaf': min_samples_leaf,\r\n",
    "               'bootstrap': bootstrap}\r\n",
    "print(random_grid)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'n_estimators': [30, 37, 45, 53, 61, 68, 76, 84, 92, 100], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, None], 'min_samples_split': [2, 3], 'min_samples_leaf': [1, 2], 'bootstrap': [True, False]}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "source": [
    "# rf = RandomForestRegressor()\r\n",
    "# rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 20, cv = 3, verbose=2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "source": [
    "X = mergred.drop(columns=['_headline', '_stock', '_headline_cleaned', '_open', '_close', 'stockPriceChange', '_headline_sentence'])\r\n",
    "y= mergred['stockPriceChange']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "source": [
    "# Fit the random search model\r\n",
    "# rf_random.fit(X, y)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "[CV] END bootstrap=False, max_depth=50, max_features=auto, min_samples_leaf=2, min_samples_split=3, n_estimators=61; total time=  17.4s\n",
      "[CV] END bootstrap=False, max_depth=50, max_features=auto, min_samples_leaf=2, min_samples_split=3, n_estimators=61; total time=  15.9s\n",
      "[CV] END bootstrap=False, max_depth=50, max_features=auto, min_samples_leaf=2, min_samples_split=3, n_estimators=61; total time=  16.1s\n",
      "[CV] END bootstrap=False, max_depth=50, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=30; total time=   8.5s\n",
      "[CV] END bootstrap=False, max_depth=50, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=30; total time=   8.3s\n",
      "[CV] END bootstrap=False, max_depth=50, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=30; total time=   8.3s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=37; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=37; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=37; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=76; total time=  13.5s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=76; total time=  12.6s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=76; total time=  12.7s\n",
      "[CV] END bootstrap=False, max_depth=40, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=45; total time=  10.2s\n",
      "[CV] END bootstrap=False, max_depth=40, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=45; total time=  10.8s\n",
      "[CV] END bootstrap=False, max_depth=40, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=45; total time=  11.4s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=auto, min_samples_leaf=1, min_samples_split=3, n_estimators=68; total time=  13.6s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=auto, min_samples_leaf=1, min_samples_split=3, n_estimators=68; total time=  12.2s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=auto, min_samples_leaf=1, min_samples_split=3, n_estimators=68; total time=  13.2s\n",
      "[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=76; total time= 2.9min\n",
      "[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=76; total time= 2.9min\n",
      "[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=76; total time= 2.8min\n",
      "[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=53; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=53; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=53; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=40, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=76; total time=   0.8s\n",
      "[CV] END bootstrap=False, max_depth=40, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=76; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=40, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=76; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=3, n_estimators=100; total time=  11.5s\n",
      "[CV] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=3, n_estimators=100; total time=  11.6s\n",
      "[CV] END bootstrap=False, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=3, n_estimators=100; total time=  12.0s\n",
      "[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   7.5s\n",
      "[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   7.5s\n",
      "[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   7.5s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=84; total time=   6.6s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=84; total time=   6.4s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=84; total time=   6.0s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.9s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.9s\n",
      "[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=68; total time=   5.1s\n",
      "[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=68; total time=   5.4s\n",
      "[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=68; total time=   6.0s\n",
      "[CV] END bootstrap=True, max_depth=40, max_features=auto, min_samples_leaf=2, min_samples_split=3, n_estimators=53; total time=   8.4s\n",
      "[CV] END bootstrap=True, max_depth=40, max_features=auto, min_samples_leaf=2, min_samples_split=3, n_estimators=53; total time=   7.6s\n",
      "[CV] END bootstrap=True, max_depth=40, max_features=auto, min_samples_leaf=2, min_samples_split=3, n_estimators=53; total time=   7.4s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=45; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=45; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=45; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=61; total time=  10.5s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=61; total time=  10.7s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=61; total time=  10.6s\n",
      "[CV] END bootstrap=True, max_depth=40, max_features=auto, min_samples_leaf=2, min_samples_split=3, n_estimators=68; total time=   9.9s\n",
      "[CV] END bootstrap=True, max_depth=40, max_features=auto, min_samples_leaf=2, min_samples_split=3, n_estimators=68; total time=  11.2s\n",
      "[CV] END bootstrap=True, max_depth=40, max_features=auto, min_samples_leaf=2, min_samples_split=3, n_estimators=68; total time=  10.7s\n",
      "[CV] END bootstrap=False, max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=92; total time=  16.4s\n",
      "[CV] END bootstrap=False, max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=92; total time=  16.6s\n",
      "[CV] END bootstrap=False, max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=92; total time=  17.8s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=84; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=84; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=84; total time=   0.9s\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=RandomForestRegressor(), n_iter=20,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2],\n",
       "                                        'min_samples_split': [2, 3],\n",
       "                                        'n_estimators': [30, 37, 45, 53, 61, 68,\n",
       "                                                         76, 84, 92, 100]},\n",
       "                   verbose=2)"
      ]
     },
     "metadata": {},
     "execution_count": 121
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "source": [
    "# rf_random.best_params_"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'n_estimators': 37,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 2,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 10,\n",
       " 'bootstrap': True}"
      ]
     },
     "metadata": {},
     "execution_count": 122
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "source": [
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y , test_size=0.2, random_state=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\r\n",
    "\r\n",
    "regressor = RandomForestRegressor( n_estimators=37, min_samples_split=2, min_samples_leaf=2, max_features='sqrt', max_depth=10, bootstrap=True)\r\n",
    "regressor.fit(X_train, y_train,)\r\n",
    "y_pred = regressor.predict(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "source": [
    "from sklearn import metrics\r\n",
    "import numpy as np\r\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\r\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\r\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mean Absolute Error: 3.8682958137383996\n",
      "Mean Squared Error: 66.04836475039967\n",
      "Root Mean Squared Error: 8.127014504133708\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "e9f94fa94278d1b9bbc15332e8f5dc1ba941effd7ffdca1aa2632c253aefc311"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}