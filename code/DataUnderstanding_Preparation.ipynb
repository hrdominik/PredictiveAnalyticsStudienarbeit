{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Daily Financial News for 6000+ Stocks\r\n",
    "### Some Data Understanding an Preparation for Prediction of stockpricse by the Sentiment of Headlines\r\n",
    "@author DHR <br>\r\n",
    "@author BKN <br>\r\n",
    "used Data in this Notebook: 'https://www.kaggle.com/miguelaenlle/massive-stock-news-analysis-db-for-nlpbacktests'"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Requirements"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#immport basic DataScience Modules\r\n",
    "#!! for pip-modul-list to install @see requirements.txt\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import os"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#import basic topic modelling\r\n",
    "import re\r\n",
    "from gensim.utils import simple_preprocess\r\n",
    "import gensim.corpora as corpora\r\n",
    "from pprint import pprint\r\n",
    "import gensim\r\n",
    "\r\n",
    "import pyLDAvis\r\n",
    "import pyLDAvis.gensim_models\r\n",
    "import pickle "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#import basic visualization\r\n",
    "from wordcloud import WordCloud, STOPWORDS\r\n",
    "import nltk #tokenization\r\n",
    "#nltk.download('punkt')\r\n",
    "nltk.download('stopwords')\r\n",
    "from nltk.corpus import stopwords\r\n",
    "from sklearn.feature_extraction.text import CountVectorizer\r\n",
    "import random"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#imports headline cleaning\r\n",
    "from nltk.stem import WordNetLemmatizer\r\n",
    "from nltk.corpus import stopwords\r\n",
    "from nltk.tokenize import word_tokenize\r\n",
    "import re\r\n",
    "import spacy\r\n",
    "from nltk.corpus import sentiwordnet as swn\r\n",
    "from nltk.corpus import wordnet as wn\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#import basic api requirements\r\n",
    "from polygon import RESTClient\r\n",
    "import datetime\r\n",
    "import time\r\n",
    "from dotenv import load_dotenv\r\n",
    "load_dotenv()\r\n",
    "\r\n",
    "def unique(l):\r\n",
    "    ## list of only the unique values from a given list\r\n",
    "    x = np.array(l)\r\n",
    "    return np.unique(x)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Load Data\r\n",
    "data = pd.read_csv('../data/raw_analyst_ratings.csv')\r\n",
    "#colums: id,headline,url,publisher,date,stock"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Understanding\r\n",
    "\r\n",
    "No Data Cleaning"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#first Look\r\n",
    "print(data.columns)\r\n",
    "data.sample(7)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#statistics\r\n",
    "print(\"observations: {}, features: {} \\n\".format(data.shape[0], data.shape[1]))\r\n",
    "print(\"unique headlines: {}, unique stocks: {} \\n\".format(len(data.headline.unique()), len(data.stock.unique())))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data.count()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "stock = data.groupby(\"stock\")\r\n",
    "stock.sample()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "stock.describe()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data['date']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data Visualization"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# BoxPlot of Stocks\r\n",
    "data['stock'].value_counts().plot.box(vert=False, figsize=(30,10))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# BocPlot of Date\r\n",
    "data['date'].value_counts().plot.box(vert=False, figsize=(30,10))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Number of Headlines by Stock\r\n",
    "plt.figure(figsize=(30,10))\r\n",
    "ax = stock.size().sort_values(ascending=False)[0:6204].plot.bar()\r\n",
    "plt.xticks(rotation=50)\r\n",
    "plt.xlabel(\"Stock\")\r\n",
    "plt.ylabel(\"Number of Headlines\")\r\n",
    "#only display every n Label\r\n",
    "n = 50\r\n",
    "for i, t in enumerate(ax.get_xticklabels()):\r\n",
    "    if (i % n) != 0:\r\n",
    "        t.set_visible(False)\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Number of Headlines by Date\r\n",
    "date = data.groupby(\"date\")\r\n",
    "\r\n",
    "plt.figure(figsize=(30,10))\r\n",
    "ax = date.size().sort_values(ascending=False)[0:1000].plot.bar()\r\n",
    "plt.xticks(rotation=50)\r\n",
    "plt.xlabel(\"Date\")\r\n",
    "plt.ylabel(\"Number of Headlines\")\r\n",
    "\r\n",
    "#only display every n Label\r\n",
    "n = 50\r\n",
    "for i, t in enumerate(ax.get_xticklabels()):\r\n",
    "    if (i % n) != 0:\r\n",
    "        t.set_visible(False)\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "date_withYear = data.assign(year = lambda dataframe: dataframe['date'].map(lambda date: date[0:4]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Der Datensatz erstreckt sich über einen Datumsspanne vom \"+ data['date'].min()[0:10] +\" bis zum \"+ data['date'].max()[0:10] +\"\\nDabei besteht der Datensatz aus \"+ str(data.headline.count()) + \" Einträgen\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Number of Date by Year\r\n",
    "year = date_withYear.groupby(\"year\")\r\n",
    "\r\n",
    "plt.figure(figsize=(30,10))\r\n",
    "year.size().plot.bar()\r\n",
    "plt.xticks(rotation=50)\r\n",
    "plt.xlabel(\"Year\")\r\n",
    "plt.ylabel(\"Number of Healines\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import statistics\r\n",
    "\r\n",
    "print(statistics.mean(year.size()))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Termdocument Matrix\r\n",
    "\r\n",
    "# all headlines as String in List\r\n",
    "docs = []\r\n",
    "for headline in data.headline:\r\n",
    "    docs.append(headline)\r\n",
    "docs = docs[0:1000]\r\n",
    "\r\n",
    "vec = CountVectorizer()\r\n",
    "X = vec.fit_transform(docs)\r\n",
    "df = pd.DataFrame(X.toarray(), columns=vec.get_feature_names())\r\n",
    "print(df)\r\n",
    "\r\n",
    "# !! TDM just useful for stemmend and removed Stopwords dataset"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Wordclouds before Data Cleaning"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Wordcloud for all Headlines\r\n",
    "\r\n",
    "#combine all headlines to one text\r\n",
    "text = \" \".join(headline for headline in data.headline)\r\n",
    "maxWords = 50\r\n",
    "#wordcloud\r\n",
    "#!! No Stopword removal\r\n",
    "# stopwords = STOPWORDS\r\n",
    "# stopwords.update([\"Benzinga\", \"Stocks\", \"vs\", \"Est\", \"EPS\"])\r\n",
    "wordcloud = WordCloud(max_words=maxWords).generate(text)\r\n",
    "\r\n",
    "#plot\r\n",
    "print(\"WorldCloud over all Stocks, Top \" + str(maxWords) + \" Words:\")\r\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\r\n",
    "plt.axis(\"off\")\r\n",
    "plt.show()\r\n",
    "\r\n",
    "#save\r\n",
    "wordcloud.to_file(\"./results/wordcloud.png\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Wordcloud for one Stock\r\n",
    "\r\n",
    "#combine all headlines of one Stock\r\n",
    "stockFilter = random.choice(unique(data['stock']))\r\n",
    "maxWords = 50\r\n",
    "text_SpecificStock = \" \".join(headline for headline in data[data[\"stock\"]==stockFilter].headline)\r\n",
    "\r\n",
    "#wordcloud\r\n",
    "#!! No Stopword removal\r\n",
    "wordcloud = WordCloud(max_words=maxWords).generate(text_SpecificStock)\r\n",
    "\r\n",
    "#plot\r\n",
    "print(\"WorldCloud for Random Stock: \" + stockFilter + \", Top \" + str(maxWords) + \" Words:\")\r\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\r\n",
    "plt.axis(\"off\")\r\n",
    "plt.show()\r\n",
    "\r\n",
    "#save\r\n",
    "wordcloud.to_file(\"./results/wordcloud_stock-\"+ stockFilter +\".png\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Top n-Words\r\n",
    "n = 20\r\n",
    "\r\n",
    "wordFreq = WordCloud().process_text(text)\r\n",
    "wordFreq = dict(sorted(wordFreq.items(), key=lambda item: item[1], reverse=True)[:n])\r\n",
    "\r\n",
    "plt.bar(range(len(wordFreq)), list(wordFreq.values()), align='center')\r\n",
    "plt.xticks(range(len(wordFreq)), list(wordFreq.keys()), rotation=50)\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Topic Modelling before Data Cleaning"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Topic Modelling with topicCount Topics\r\n",
    "topicCount = 10\r\n",
    "\r\n",
    "## Necessary Text Cleaning\r\n",
    "# Remove punctuation\r\n",
    "# data['headline_processed'] = \\\r\n",
    "# data['headline'].map(lambda x: re.sub('[,\\.!?]', '', x))\r\n",
    "# Convert the titles to lowercase\r\n",
    "# data['headline_processed'] = \\\r\n",
    "# data['headline_processed'].map(lambda x: x.lower())\r\n",
    "\r\n",
    "# stop_words = stopwords.words('english')\r\n",
    "# stop_words.extend(['bezinga', 'stock'])\r\n",
    "\r\n",
    "## Necessary Tokenzisation of Sentences to Words\r\n",
    "def sent_to_words(sentences):\r\n",
    "    for sentence in sentences:\r\n",
    "        # deacc=True removes punctuations\r\n",
    "        yield(simple_preprocess(str(sentence), deacc=True))\r\n",
    "# def remove_stopwords(texts):\r\n",
    "#     return [[word for word in simple_preprocess(str(doc)) \r\n",
    "#              if word not in stop_words] for doc in texts]\r\n",
    "\r\n",
    "\r\n",
    "headline = data.headline.values.tolist() #use headline_processed instead of headline for a little bit of DataCleaning\r\n",
    "headline_words = list(sent_to_words(headline))\r\n",
    "# remove stop words\r\n",
    "# headline_words = remove_stopwords(headline_words)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create Dictionary\r\n",
    "id2word = corpora.Dictionary(headline_words)\r\n",
    "# Create Corpus\r\n",
    "texts = headline_words\r\n",
    "# Term Document Frequency\r\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# The Real Topic Modelling\r\n",
    "# Build LDA model\r\n",
    "lda_model = gensim.models.LdaMulticore(corpus=corpus,\r\n",
    "                                       id2word=id2word,\r\n",
    "                                       num_topics=topicCount)\r\n",
    "# Print the Keyword in the topics\r\n",
    "pprint(lda_model.print_topics())\r\n",
    "doc_lda = lda_model[corpus]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Visualization of the Topic Modelling\r\n",
    "\r\n",
    "pyLDAvis.enable_notebook()\r\n",
    "LDAvis_data_filepath = os.path.join('./app/results_ldavis_prepared_'+str(topicCount))\r\n",
    "# # this is a bit time consuming - make the if statement True\r\n",
    "# # if you want to execute visualization prep yourself\r\n",
    "if 1 == 1:\r\n",
    "    LDAvis_prepared = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word)\r\n",
    "    with open(LDAvis_data_filepath, 'wb') as f:\r\n",
    "        pickle.dump(LDAvis_prepared, f)\r\n",
    "# load the pre-prepared pyLDAvis data from disk\r\n",
    "with open(LDAvis_data_filepath, 'rb') as f:\r\n",
    "    LDAvis_prepared = pickle.load(f)\r\n",
    "pyLDAvis.save_html(LDAvis_prepared, './app/results_ldavis_prepared_'+ str(topicCount) +'.html')\r\n",
    "LDAvis_prepared"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data Quality"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# count all null values in the DataFrame\r\n",
    "print(\"Anzahl von null Werten im gesamten DataFrame: \"+str(data.isna().sum().sum()))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# count all dates without time, no need to format in isoFormat\r\n",
    "print(\"Anzahl Zeitstempel ohne konkrete Uhrzeit: \"+ str(data['date'].str.count('00:00:00').sum()))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# count duplicated\r\n",
    "print(\"Anzahl Doppelten Einträgen: \"+ str(data.duplicated().sum()))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Preparation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Clean"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# format datetime to date\r\n",
    "data = data.assign(\r\n",
    "    date = lambda dataframe: dataframe['date'].map(lambda date: date[0:10])\r\n",
    ")\r\n",
    "\r\n",
    "# delete all rows older than 2years\r\n",
    "data = data.drop(data[data.date < '2019-08-21'].index)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Der Datensatz erstreckt sich nun über einen Datumsspanne vom \"+ data['date'].min() +\" bis zum \"+ data['date'].max() +\"\\nDabei besteht der Datensatz jetzt aus \"+ str(data.headline.count()) + \" Einträgen\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Headline Cleaning\r\n",
    "### Hier wird nochmal speziell jede einzelene Headline mit WordNet den typischen pre-processing Schritten unterzogen"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "source": [
    "#Daten laden und eine weitere Spalte mit den gecleanten Headlines erstelleb\r\n",
    "data_important = data[:10]\r\n",
    "data_temp = data_important['headline'].copy()\r\n",
    "\r\n",
    "data_important['headlines_cleaned'] = data_temp\r\n",
    "\r\n",
    "data_important.head()\r\n",
    "\r\n",
    "nltk.download('wordnet')\r\n",
    "nltk.download('averaged_perceptron_tagger')\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\kaste\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:3607: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._set_item(key, value)\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\kaste\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\kaste\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 93
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "source": [
    "#POS Tagging\r\n",
    "import datetime\r\n",
    "def tokenize_post(headline):\r\n",
    "    hl_tokenz = word_tokenize(headline)\r\n",
    "    hl_post = nltk.pos_tag(hl_tokenz)\r\n",
    "    hl_post_result = []\r\n",
    "    for word in hl_post:\r\n",
    "        if word[1].startswith('NN'):\r\n",
    "            hl_post_result.append([word[0], 'n'])\r\n",
    "        elif word[1].startswith('JJ'):\r\n",
    "            hl_post_result.append([word[0], 'a'])\r\n",
    "        elif word[1].startswith('V'):\r\n",
    "            hl_post_result.append([word[0], 'v'])\r\n",
    "        elif word[1].startswith('R'):\r\n",
    "            hl_post_result.append([word[0], 'r'])\r\n",
    "        else:\r\n",
    "            hl_post_result.append([word[0], ''])\r\n",
    "    return hl_post_result\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "source": [
    "data_important['headlines_cleaned'] = data_important['headlines_cleaned'].apply(tokenize_post)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "source": [
    "data_important['headlines_cleaned'].head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    [[Stocks, n], [That, ], [Hit, v], [52-Week, a]...\n",
       "1    [[Stocks, n], [That, ], [Hit, v], [52-Week, a]...\n",
       "2    [[71, ], [Biggest, a], [Movers, n], [From, ], ...\n",
       "3    [[46, ], [Stocks, n], [Moving, v], [In, ], [Fr...\n",
       "4    [[B, n], [of, ], [A, n], [Securities, n], [Mai...\n",
       "Name: headlines_cleaned, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 96
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "CC coordinating conjunction\r\n",
    "CD cardinal digit\r\n",
    "DT determiner\r\n",
    "EX existential there (like: “there is” … think of it like “there exists”)\r\n",
    "FW foreign word\r\n",
    "IN preposition/subordinating conjunction\r\n",
    "JJ adjective ‘big’\r\n",
    "JJR adjective, comparative ‘bigger’\r\n",
    "JJS adjective, superlative ‘biggest’\r\n",
    "LS list marker 1)\r\n",
    "MD modal could, will\r\n",
    "NN noun, singular ‘desk’\r\n",
    "NNS noun plural ‘desks’\r\n",
    "NNP proper noun, singular ‘Harrison’\r\n",
    "NNPS proper noun, plural ‘Americans’\r\n",
    "PDT predeterminer ‘all the kids’\r\n",
    "POS possessive ending parent’s\r\n",
    "PRP personal pronoun I, he, she\r\n",
    "PRP$ possessive pronoun my, his, hers\r\n",
    "RB adverb very, silently,\r\n",
    "RBR adverb, comparative better\r\n",
    "RBS adverb, superlative best\r\n",
    "RP particle give up\r\n",
    "TO, to go ‘to’ the store.\r\n",
    "UH interjection, errrrrrrrm\r\n",
    "VB verb, base form take\r\n",
    "VBD verb, past tense took\r\n",
    "VBG verb, gerund/present participle taking\r\n",
    "VBN verb, past participle taken\r\n",
    "VBP verb, sing. present, non-3d take\r\n",
    "VBZ verb, 3rd person sing. present takes\r\n",
    "WDT wh-determiner which\r\n",
    "WP wh-pronoun who, what\r\n",
    "WP$ possessive wh-pronoun whose\r\n",
    "WRB wh-abverb where, when"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data_important.to_csv('../data/data_post_tokenz')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "source": [
    "#funktionen für Lowercase und Stopword-removal und Tokenization\r\n",
    "\r\n",
    "def lowercase(headline_post_tok):\r\n",
    "    hl_post_tok_lower = []\r\n",
    "    for word_pos in headline_post_tok:\r\n",
    "        hl_post_tok_lower.append(tuple([word_pos[0].lower(), word_pos[1]]))\r\n",
    "    return hl_post_tok_lower\r\n",
    "    \r\n",
    "#function for removing stopwords and tokenize using Wordnet\r\n",
    "\r\n",
    "def remove_stopwords(hl_post_tok_lower):\r\n",
    "    stop_words = set(stopwords.words('english')) \r\n",
    "\r\n",
    "    #add some custom stopword here\r\n",
    "    # stop_words.add('')\r\n",
    "\r\n",
    "    filtered_sentence = [word for word in hl_post_tok_lower if not word[0] in stop_words]\r\n",
    "    return filtered_sentence\r\n",
    "    \r\n",
    "\r\n",
    "\r\n",
    "    \r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "source": [
    "#Headlines lowercase machen .... ja das geht auch mit lambda\r\n",
    "data_important['headlines_cleaned'] = data_important['headlines_cleaned'].apply(lowercase)\r\n",
    "data_important.head()\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Unnamed: 0                                           headline  \\\n",
       "0           0            Stocks That Hit 52-Week Highs On Friday   \n",
       "1           1         Stocks That Hit 52-Week Highs On Wednesday   \n",
       "2           2                      71 Biggest Movers From Friday   \n",
       "3           3       46 Stocks Moving In Friday's Mid-Day Session   \n",
       "4           4  B of A Securities Maintains Neutral on Agilent...   \n",
       "\n",
       "                                                 url          publisher  \\\n",
       "0  https://www.benzinga.com/news/20/06/16190091/s...  Benzinga Insights   \n",
       "1  https://www.benzinga.com/news/20/06/16170189/s...  Benzinga Insights   \n",
       "2  https://www.benzinga.com/news/20/05/16103463/7...         Lisa Levin   \n",
       "3  https://www.benzinga.com/news/20/05/16095921/4...         Lisa Levin   \n",
       "4  https://www.benzinga.com/news/20/05/16095304/b...         Vick Meyer   \n",
       "\n",
       "                        date stock  \\\n",
       "0  2020-06-05 10:30:54-04:00     A   \n",
       "1  2020-06-03 10:45:20-04:00     A   \n",
       "2  2020-05-26 04:30:07-04:00     A   \n",
       "3  2020-05-22 12:45:06-04:00     A   \n",
       "4  2020-05-22 11:38:59-04:00     A   \n",
       "\n",
       "                                   headlines_cleaned  \n",
       "0  [(stocks, n), (that, ), (hit, v), (52-week, a)...  \n",
       "1  [(stocks, n), (that, ), (hit, v), (52-week, a)...  \n",
       "2  [(71, ), (biggest, a), (movers, n), (from, ), ...  \n",
       "3  [(46, ), (stocks, n), (moving, v), (in, ), (fr...  \n",
       "4  [(b, n), (of, ), (a, n), (securities, n), (mai...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>headline</th>\n",
       "      <th>url</th>\n",
       "      <th>publisher</th>\n",
       "      <th>date</th>\n",
       "      <th>stock</th>\n",
       "      <th>headlines_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Stocks That Hit 52-Week Highs On Friday</td>\n",
       "      <td>https://www.benzinga.com/news/20/06/16190091/s...</td>\n",
       "      <td>Benzinga Insights</td>\n",
       "      <td>2020-06-05 10:30:54-04:00</td>\n",
       "      <td>A</td>\n",
       "      <td>[(stocks, n), (that, ), (hit, v), (52-week, a)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Stocks That Hit 52-Week Highs On Wednesday</td>\n",
       "      <td>https://www.benzinga.com/news/20/06/16170189/s...</td>\n",
       "      <td>Benzinga Insights</td>\n",
       "      <td>2020-06-03 10:45:20-04:00</td>\n",
       "      <td>A</td>\n",
       "      <td>[(stocks, n), (that, ), (hit, v), (52-week, a)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>71 Biggest Movers From Friday</td>\n",
       "      <td>https://www.benzinga.com/news/20/05/16103463/7...</td>\n",
       "      <td>Lisa Levin</td>\n",
       "      <td>2020-05-26 04:30:07-04:00</td>\n",
       "      <td>A</td>\n",
       "      <td>[(71, ), (biggest, a), (movers, n), (from, ), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>46 Stocks Moving In Friday's Mid-Day Session</td>\n",
       "      <td>https://www.benzinga.com/news/20/05/16095921/4...</td>\n",
       "      <td>Lisa Levin</td>\n",
       "      <td>2020-05-22 12:45:06-04:00</td>\n",
       "      <td>A</td>\n",
       "      <td>[(46, ), (stocks, n), (moving, v), (in, ), (fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>B of A Securities Maintains Neutral on Agilent...</td>\n",
       "      <td>https://www.benzinga.com/news/20/05/16095304/b...</td>\n",
       "      <td>Vick Meyer</td>\n",
       "      <td>2020-05-22 11:38:59-04:00</td>\n",
       "      <td>A</td>\n",
       "      <td>[(b, n), (of, ), (a, n), (securities, n), (mai...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 98
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "source": [
    "#jetzt das stopword removal mit tokenization\r\n",
    "#!! das kann etwas zeitaufwendig sein, deshalb wird das Ergebnis im nächsten Schritt als csv exportiert und liegt im Ordner ab.\r\n",
    "data_important['headlines_cleaned'] = data_important['headlines_cleaned'].apply(remove_stopwords)\r\n",
    "data_important.head()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\kaste\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:3607: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._set_item(key, value)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Unnamed: 0                                           headline  \\\n",
       "0           0            Stocks That Hit 52-Week Highs On Friday   \n",
       "1           1         Stocks That Hit 52-Week Highs On Wednesday   \n",
       "2           2                      71 Biggest Movers From Friday   \n",
       "3           3       46 Stocks Moving In Friday's Mid-Day Session   \n",
       "4           4  B of A Securities Maintains Neutral on Agilent...   \n",
       "\n",
       "                                                 url          publisher  \\\n",
       "0  https://www.benzinga.com/news/20/06/16190091/s...  Benzinga Insights   \n",
       "1  https://www.benzinga.com/news/20/06/16170189/s...  Benzinga Insights   \n",
       "2  https://www.benzinga.com/news/20/05/16103463/7...         Lisa Levin   \n",
       "3  https://www.benzinga.com/news/20/05/16095921/4...         Lisa Levin   \n",
       "4  https://www.benzinga.com/news/20/05/16095304/b...         Vick Meyer   \n",
       "\n",
       "                        date stock  \\\n",
       "0  2020-06-05 10:30:54-04:00     A   \n",
       "1  2020-06-03 10:45:20-04:00     A   \n",
       "2  2020-05-26 04:30:07-04:00     A   \n",
       "3  2020-05-22 12:45:06-04:00     A   \n",
       "4  2020-05-22 11:38:59-04:00     A   \n",
       "\n",
       "                                   headlines_cleaned  \n",
       "0  [(stocks, n), (hit, v), (52-week, a), (highs, ...  \n",
       "1  [(stocks, n), (hit, v), (52-week, a), (highs, ...  \n",
       "2   [(71, ), (biggest, a), (movers, n), (friday, n)]  \n",
       "3  [(46, ), (stocks, n), (moving, v), (friday, n)...  \n",
       "4  [(b, n), (securities, n), (maintains, n), (neu...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>headline</th>\n",
       "      <th>url</th>\n",
       "      <th>publisher</th>\n",
       "      <th>date</th>\n",
       "      <th>stock</th>\n",
       "      <th>headlines_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Stocks That Hit 52-Week Highs On Friday</td>\n",
       "      <td>https://www.benzinga.com/news/20/06/16190091/s...</td>\n",
       "      <td>Benzinga Insights</td>\n",
       "      <td>2020-06-05 10:30:54-04:00</td>\n",
       "      <td>A</td>\n",
       "      <td>[(stocks, n), (hit, v), (52-week, a), (highs, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Stocks That Hit 52-Week Highs On Wednesday</td>\n",
       "      <td>https://www.benzinga.com/news/20/06/16170189/s...</td>\n",
       "      <td>Benzinga Insights</td>\n",
       "      <td>2020-06-03 10:45:20-04:00</td>\n",
       "      <td>A</td>\n",
       "      <td>[(stocks, n), (hit, v), (52-week, a), (highs, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>71 Biggest Movers From Friday</td>\n",
       "      <td>https://www.benzinga.com/news/20/05/16103463/7...</td>\n",
       "      <td>Lisa Levin</td>\n",
       "      <td>2020-05-26 04:30:07-04:00</td>\n",
       "      <td>A</td>\n",
       "      <td>[(71, ), (biggest, a), (movers, n), (friday, n)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>46 Stocks Moving In Friday's Mid-Day Session</td>\n",
       "      <td>https://www.benzinga.com/news/20/05/16095921/4...</td>\n",
       "      <td>Lisa Levin</td>\n",
       "      <td>2020-05-22 12:45:06-04:00</td>\n",
       "      <td>A</td>\n",
       "      <td>[(46, ), (stocks, n), (moving, v), (friday, n)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>B of A Securities Maintains Neutral on Agilent...</td>\n",
       "      <td>https://www.benzinga.com/news/20/05/16095304/b...</td>\n",
       "      <td>Vick Meyer</td>\n",
       "      <td>2020-05-22 11:38:59-04:00</td>\n",
       "      <td>A</td>\n",
       "      <td>[(b, n), (securities, n), (maintains, n), (neu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 99
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Export als csv\r\n",
    "data_important.to_csv('../data/zwischenergebnis_stopwords_tokenized.csv', index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "source": [
    "#Hier eine Lemmatisierungsfunktion mit dem WortNetLemmatizer\r\n",
    "lemmatizer = WordNetLemmatizer()\r\n",
    "\r\n",
    "#this headline is pos-tagged, tokenzied, lower, and stopwords-removed\r\n",
    "def lemmatize(headline):\r\n",
    "    lemmatized_output = []\r\n",
    "    for word in headline:\r\n",
    "        if word[1] == '':\r\n",
    "            lemmatized_output.append((lemmatizer.lemmatize(word[0]), word[1]))\r\n",
    "        else:\r\n",
    "            lemmatized_output.append((lemmatizer.lemmatize(word[0], pos=word[1]), word[1]))\r\n",
    "\r\n",
    "    #Alle Wörter mit weniger als zwei Zeichen weg\r\n",
    "    lemmatized_output = [word for word in lemmatized_output if len(word[0]) > 2]\r\n",
    "\r\n",
    "    #Alle Zahlen entfernen\r\n",
    "    lemmatized_output = [word for word in lemmatized_output if not word[0].isnumeric()]\r\n",
    "\r\n",
    "    return lemmatized_output\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "source": [
    "#lemmatization durchführen\r\n",
    "\r\n",
    "#nächste Zeile um daten zu laden\r\n",
    "# data_important = pd.read_csv('../data/zwischenergebnis_stopwords_tokenized.csv')\r\n",
    "data_important['headlines_cleaned'] = data_important['headlines_cleaned'].apply(lemmatize)\r\n",
    "data_important.head()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\kaste\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:3607: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._set_item(key, value)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Unnamed: 0                                           headline  \\\n",
       "0           0            Stocks That Hit 52-Week Highs On Friday   \n",
       "1           1         Stocks That Hit 52-Week Highs On Wednesday   \n",
       "2           2                      71 Biggest Movers From Friday   \n",
       "3           3       46 Stocks Moving In Friday's Mid-Day Session   \n",
       "4           4  B of A Securities Maintains Neutral on Agilent...   \n",
       "\n",
       "                                                 url          publisher  \\\n",
       "0  https://www.benzinga.com/news/20/06/16190091/s...  Benzinga Insights   \n",
       "1  https://www.benzinga.com/news/20/06/16170189/s...  Benzinga Insights   \n",
       "2  https://www.benzinga.com/news/20/05/16103463/7...         Lisa Levin   \n",
       "3  https://www.benzinga.com/news/20/05/16095921/4...         Lisa Levin   \n",
       "4  https://www.benzinga.com/news/20/05/16095304/b...         Vick Meyer   \n",
       "\n",
       "                        date stock  \\\n",
       "0  2020-06-05 10:30:54-04:00     A   \n",
       "1  2020-06-03 10:45:20-04:00     A   \n",
       "2  2020-05-26 04:30:07-04:00     A   \n",
       "3  2020-05-22 12:45:06-04:00     A   \n",
       "4  2020-05-22 11:38:59-04:00     A   \n",
       "\n",
       "                                   headlines_cleaned  \n",
       "0  [(stock, n), (hit, v), (52-week, a), (high, n)...  \n",
       "1  [(stock, n), (hit, v), (52-week, a), (high, n)...  \n",
       "2                [(big, a), (mover, n), (friday, n)]  \n",
       "3  [(stock, n), (move, v), (friday, n), (mid-day,...  \n",
       "4  [(security, n), (maintains, n), (neutral, n), ...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>headline</th>\n",
       "      <th>url</th>\n",
       "      <th>publisher</th>\n",
       "      <th>date</th>\n",
       "      <th>stock</th>\n",
       "      <th>headlines_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Stocks That Hit 52-Week Highs On Friday</td>\n",
       "      <td>https://www.benzinga.com/news/20/06/16190091/s...</td>\n",
       "      <td>Benzinga Insights</td>\n",
       "      <td>2020-06-05 10:30:54-04:00</td>\n",
       "      <td>A</td>\n",
       "      <td>[(stock, n), (hit, v), (52-week, a), (high, n)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Stocks That Hit 52-Week Highs On Wednesday</td>\n",
       "      <td>https://www.benzinga.com/news/20/06/16170189/s...</td>\n",
       "      <td>Benzinga Insights</td>\n",
       "      <td>2020-06-03 10:45:20-04:00</td>\n",
       "      <td>A</td>\n",
       "      <td>[(stock, n), (hit, v), (52-week, a), (high, n)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>71 Biggest Movers From Friday</td>\n",
       "      <td>https://www.benzinga.com/news/20/05/16103463/7...</td>\n",
       "      <td>Lisa Levin</td>\n",
       "      <td>2020-05-26 04:30:07-04:00</td>\n",
       "      <td>A</td>\n",
       "      <td>[(big, a), (mover, n), (friday, n)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>46 Stocks Moving In Friday's Mid-Day Session</td>\n",
       "      <td>https://www.benzinga.com/news/20/05/16095921/4...</td>\n",
       "      <td>Lisa Levin</td>\n",
       "      <td>2020-05-22 12:45:06-04:00</td>\n",
       "      <td>A</td>\n",
       "      <td>[(stock, n), (move, v), (friday, n), (mid-day,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>B of A Securities Maintains Neutral on Agilent...</td>\n",
       "      <td>https://www.benzinga.com/news/20/05/16095304/b...</td>\n",
       "      <td>Vick Meyer</td>\n",
       "      <td>2020-05-22 11:38:59-04:00</td>\n",
       "      <td>A</td>\n",
       "      <td>[(security, n), (maintains, n), (neutral, n), ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 101
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Export als csv\r\n",
    "data_important.to_csv('../data/zwischenergebnis_lemmatized.csv', index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "source": [
    "def getSynset(headline):\r\n",
    "    synset_output = []\r\n",
    "    for word in headline:\r\n",
    "        synsets = wn.synsets(word[0], pos=word[1])\r\n",
    "        if len(synsets)>0:\r\n",
    "            synset_output.append((synsets[0].name()))\r\n",
    "        # wort entfernen wenn kein senitment verfügbar\r\n",
    "        # else:\r\n",
    "        #     synset_output.append(word[0]+ \".\" +word[1]+\".01\")\r\n",
    "    return synset_output"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "source": [
    "# getSentiment([('big', 'a'), ('mover', 'n'), ('friday', 'n')])\r\n",
    "data_important['headlines_cleaned'] = data_important['headlines_cleaned'].apply(getSynset)\r\n",
    "data_important.head()\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\kaste\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:3607: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._set_item(key, value)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Unnamed: 0                                           headline  \\\n",
       "0           0            Stocks That Hit 52-Week Highs On Friday   \n",
       "1           1         Stocks That Hit 52-Week Highs On Wednesday   \n",
       "2           2                      71 Biggest Movers From Friday   \n",
       "3           3       46 Stocks Moving In Friday's Mid-Day Session   \n",
       "4           4  B of A Securities Maintains Neutral on Agilent...   \n",
       "\n",
       "                                                 url          publisher  \\\n",
       "0  https://www.benzinga.com/news/20/06/16190091/s...  Benzinga Insights   \n",
       "1  https://www.benzinga.com/news/20/06/16170189/s...  Benzinga Insights   \n",
       "2  https://www.benzinga.com/news/20/05/16103463/7...         Lisa Levin   \n",
       "3  https://www.benzinga.com/news/20/05/16095921/4...         Lisa Levin   \n",
       "4  https://www.benzinga.com/news/20/05/16095304/b...         Vick Meyer   \n",
       "\n",
       "                        date stock  \\\n",
       "0  2020-06-05 10:30:54-04:00     A   \n",
       "1  2020-06-03 10:45:20-04:00     A   \n",
       "2  2020-05-26 04:30:07-04:00     A   \n",
       "3  2020-05-22 12:45:06-04:00     A   \n",
       "4  2020-05-22 11:38:59-04:00     A   \n",
       "\n",
       "                                   headlines_cleaned  \n",
       "0     [stock.n.01, hit.v.01, high.n.01, friday.n.01]  \n",
       "1  [stock.n.01, hit.v.01, high.n.01, wednesday.n.01]  \n",
       "2              [large.a.01, mover.n.01, friday.n.01]  \n",
       "3  [stock.n.01, travel.v.01, friday.n.01, session...  \n",
       "4  [security.n.01, neutral.n.01, technology.n.01,...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>headline</th>\n",
       "      <th>url</th>\n",
       "      <th>publisher</th>\n",
       "      <th>date</th>\n",
       "      <th>stock</th>\n",
       "      <th>headlines_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Stocks That Hit 52-Week Highs On Friday</td>\n",
       "      <td>https://www.benzinga.com/news/20/06/16190091/s...</td>\n",
       "      <td>Benzinga Insights</td>\n",
       "      <td>2020-06-05 10:30:54-04:00</td>\n",
       "      <td>A</td>\n",
       "      <td>[stock.n.01, hit.v.01, high.n.01, friday.n.01]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Stocks That Hit 52-Week Highs On Wednesday</td>\n",
       "      <td>https://www.benzinga.com/news/20/06/16170189/s...</td>\n",
       "      <td>Benzinga Insights</td>\n",
       "      <td>2020-06-03 10:45:20-04:00</td>\n",
       "      <td>A</td>\n",
       "      <td>[stock.n.01, hit.v.01, high.n.01, wednesday.n.01]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>71 Biggest Movers From Friday</td>\n",
       "      <td>https://www.benzinga.com/news/20/05/16103463/7...</td>\n",
       "      <td>Lisa Levin</td>\n",
       "      <td>2020-05-26 04:30:07-04:00</td>\n",
       "      <td>A</td>\n",
       "      <td>[large.a.01, mover.n.01, friday.n.01]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>46 Stocks Moving In Friday's Mid-Day Session</td>\n",
       "      <td>https://www.benzinga.com/news/20/05/16095921/4...</td>\n",
       "      <td>Lisa Levin</td>\n",
       "      <td>2020-05-22 12:45:06-04:00</td>\n",
       "      <td>A</td>\n",
       "      <td>[stock.n.01, travel.v.01, friday.n.01, session...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>B of A Securities Maintains Neutral on Agilent...</td>\n",
       "      <td>https://www.benzinga.com/news/20/05/16095304/b...</td>\n",
       "      <td>Vick Meyer</td>\n",
       "      <td>2020-05-22 11:38:59-04:00</td>\n",
       "      <td>A</td>\n",
       "      <td>[security.n.01, neutral.n.01, technology.n.01,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 103
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "source": [
    "nltk.download('sentiwordnet')\r\n",
    "senti_pos_score = []\r\n",
    "senti_neg_score = []\r\n",
    "\r\n",
    "senti_score = []\r\n",
    "# senti_obj_score = []\r\n",
    "\r\n",
    "def getSentiment(headline):\r\n",
    "    senti_pos = 0\r\n",
    "    senti_neg = 0\r\n",
    "    # senti_obj = 0\r\n",
    "    for word in headline:\r\n",
    "        swn_synset = swn.senti_synset(word)\r\n",
    "        senti_pos += swn_synset.pos_score()\r\n",
    "        senti_neg += swn_synset.neg_score()\r\n",
    "\r\n",
    "    senti_pos_score.append(senti_pos)\r\n",
    "    senti_neg_score.append(senti_neg)\r\n",
    "\r\n",
    "    senti_score.append(senti_pos - senti_neg)\r\n",
    "    # senti_obj_score.append(swn_synset.obj_score())\r\n",
    "    return headline\r\n",
    "\r\n",
    "def addSentimentToDataFrame():\r\n",
    "    data_important['senti_pos_score'] = senti_pos_score\r\n",
    "    data_important['senti_neg_score'] = senti_neg_score\r\n",
    "    \r\n",
    "    data_important['senti_score'] = senti_score\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package sentiwordnet to\n",
      "[nltk_data]     C:\\Users\\kaste\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package sentiwordnet is already up-to-date!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "source": [
    "data_important['headlines_cleaned'] = data_important['headlines_cleaned'].apply(getSentiment)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\kaste\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:3607: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._set_item(key, value)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "source": [
    "addSentimentToDataFrame()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\kaste\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:3607: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._set_item(key, value)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "source": [
    "data_important"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Unnamed: 0                                           headline  \\\n",
       "0           0            Stocks That Hit 52-Week Highs On Friday   \n",
       "1           1         Stocks That Hit 52-Week Highs On Wednesday   \n",
       "2           2                      71 Biggest Movers From Friday   \n",
       "3           3       46 Stocks Moving In Friday's Mid-Day Session   \n",
       "4           4  B of A Securities Maintains Neutral on Agilent...   \n",
       "5           5  CFRA Maintains Hold on Agilent Technologies, L...   \n",
       "6           6  UBS Maintains Neutral on Agilent Technologies,...   \n",
       "7           7  Agilent Technologies shares are trading higher...   \n",
       "8           8  Wells Fargo Maintains Overweight on Agilent Te...   \n",
       "9           9         10 Biggest Price Target Changes For Friday   \n",
       "\n",
       "                                                 url                publisher  \\\n",
       "0  https://www.benzinga.com/news/20/06/16190091/s...        Benzinga Insights   \n",
       "1  https://www.benzinga.com/news/20/06/16170189/s...        Benzinga Insights   \n",
       "2  https://www.benzinga.com/news/20/05/16103463/7...               Lisa Levin   \n",
       "3  https://www.benzinga.com/news/20/05/16095921/4...               Lisa Levin   \n",
       "4  https://www.benzinga.com/news/20/05/16095304/b...               Vick Meyer   \n",
       "5  https://www.benzinga.com/news/20/05/16095163/c...  vishwanath@benzinga.com   \n",
       "6  https://www.benzinga.com/news/20/05/16094027/u...  vishwanath@benzinga.com   \n",
       "7  https://www.benzinga.com/wiim/20/05/16093805/a...        Benzinga Newsdesk   \n",
       "8  https://www.benzinga.com/news/20/05/16093505/w...  vishwanath@benzinga.com   \n",
       "9  https://www.benzinga.com/analyst-ratings/price...               Lisa Levin   \n",
       "\n",
       "                        date stock headlines_cleaned  senti_pos_score  \\\n",
       "0  2020-06-05 10:30:54-04:00     A              None            0.125   \n",
       "1  2020-06-03 10:45:20-04:00     A              None            0.125   \n",
       "2  2020-05-26 04:30:07-04:00     A              None            0.250   \n",
       "3  2020-05-22 12:45:06-04:00     A              None            0.000   \n",
       "4  2020-05-22 11:38:59-04:00     A              None            0.500   \n",
       "5  2020-05-22 11:23:25-04:00     A              None            0.000   \n",
       "6  2020-05-22 09:36:20-04:00     A              None            0.000   \n",
       "7  2020-05-22 09:07:04-04:00     A              None            0.125   \n",
       "8  2020-05-22 08:37:59-04:00     A              None            0.000   \n",
       "9  2020-05-22 08:06:17-04:00     A              None            0.000   \n",
       "\n",
       "   senti_neg_score  senti_score  \n",
       "0            0.000        0.125  \n",
       "1            0.000        0.125  \n",
       "2            0.125        0.125  \n",
       "3            0.000        0.000  \n",
       "4            0.250        0.250  \n",
       "5            0.125       -0.125  \n",
       "6            0.125       -0.125  \n",
       "7            0.250       -0.125  \n",
       "8            0.000        0.000  \n",
       "9            0.000        0.000  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>headline</th>\n",
       "      <th>url</th>\n",
       "      <th>publisher</th>\n",
       "      <th>date</th>\n",
       "      <th>stock</th>\n",
       "      <th>headlines_cleaned</th>\n",
       "      <th>senti_pos_score</th>\n",
       "      <th>senti_neg_score</th>\n",
       "      <th>senti_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Stocks That Hit 52-Week Highs On Friday</td>\n",
       "      <td>https://www.benzinga.com/news/20/06/16190091/s...</td>\n",
       "      <td>Benzinga Insights</td>\n",
       "      <td>2020-06-05 10:30:54-04:00</td>\n",
       "      <td>A</td>\n",
       "      <td>None</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Stocks That Hit 52-Week Highs On Wednesday</td>\n",
       "      <td>https://www.benzinga.com/news/20/06/16170189/s...</td>\n",
       "      <td>Benzinga Insights</td>\n",
       "      <td>2020-06-03 10:45:20-04:00</td>\n",
       "      <td>A</td>\n",
       "      <td>None</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>71 Biggest Movers From Friday</td>\n",
       "      <td>https://www.benzinga.com/news/20/05/16103463/7...</td>\n",
       "      <td>Lisa Levin</td>\n",
       "      <td>2020-05-26 04:30:07-04:00</td>\n",
       "      <td>A</td>\n",
       "      <td>None</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>46 Stocks Moving In Friday's Mid-Day Session</td>\n",
       "      <td>https://www.benzinga.com/news/20/05/16095921/4...</td>\n",
       "      <td>Lisa Levin</td>\n",
       "      <td>2020-05-22 12:45:06-04:00</td>\n",
       "      <td>A</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>B of A Securities Maintains Neutral on Agilent...</td>\n",
       "      <td>https://www.benzinga.com/news/20/05/16095304/b...</td>\n",
       "      <td>Vick Meyer</td>\n",
       "      <td>2020-05-22 11:38:59-04:00</td>\n",
       "      <td>A</td>\n",
       "      <td>None</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>CFRA Maintains Hold on Agilent Technologies, L...</td>\n",
       "      <td>https://www.benzinga.com/news/20/05/16095163/c...</td>\n",
       "      <td>vishwanath@benzinga.com</td>\n",
       "      <td>2020-05-22 11:23:25-04:00</td>\n",
       "      <td>A</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>-0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>UBS Maintains Neutral on Agilent Technologies,...</td>\n",
       "      <td>https://www.benzinga.com/news/20/05/16094027/u...</td>\n",
       "      <td>vishwanath@benzinga.com</td>\n",
       "      <td>2020-05-22 09:36:20-04:00</td>\n",
       "      <td>A</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>-0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Agilent Technologies shares are trading higher...</td>\n",
       "      <td>https://www.benzinga.com/wiim/20/05/16093805/a...</td>\n",
       "      <td>Benzinga Newsdesk</td>\n",
       "      <td>2020-05-22 09:07:04-04:00</td>\n",
       "      <td>A</td>\n",
       "      <td>None</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.250</td>\n",
       "      <td>-0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Wells Fargo Maintains Overweight on Agilent Te...</td>\n",
       "      <td>https://www.benzinga.com/news/20/05/16093505/w...</td>\n",
       "      <td>vishwanath@benzinga.com</td>\n",
       "      <td>2020-05-22 08:37:59-04:00</td>\n",
       "      <td>A</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>10 Biggest Price Target Changes For Friday</td>\n",
       "      <td>https://www.benzinga.com/analyst-ratings/price...</td>\n",
       "      <td>Lisa Levin</td>\n",
       "      <td>2020-05-22 08:06:17-04:00</td>\n",
       "      <td>A</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 111
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# clean the Stocks\r\n",
    "# Remove Rows with Stocks that occur less than occ times\r\n",
    "occ = 0\r\n",
    "data = data[data.groupby('stock').stock.transform(len) > occ]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Construct"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### API call to get StockPrices for all stocks that occur more than 10 times\r\n",
    "used API : 'https://polygon.io/'\r\n",
    "(need timeouts because of max 5 Api calls per Minute)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# List of Stock Ticker to call\r\n",
    "stocks_unique = unique(data['stock'])\r\n",
    "print(\"Es verbleiben \"+str(len(stocks_unique))+\" eindeutige Stocks, zur Anfrage an der API, welche im Zeitraum der Verfügbaren API liegen\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# API call with TimeOut (5 per minute)\r\n",
    "key = os.environ.get(\"POLYGON_IO_API_KEY\")\r\n",
    "apiResults = []\r\n",
    "apiCount = 0\r\n",
    "\r\n",
    "for s in stocks_unique:\r\n",
    "    # the API only response to 2years historical dates\r\n",
    "    from_ = '2019-08-21'\r\n",
    "    to =  '2020-12-31'\r\n",
    "\r\n",
    "    #The API call\r\n",
    "    with RESTClient(key) as client:\r\n",
    "        resp = client.stocks_equities_aggregates(s, 1, \"day\", from_, to, unadjusted=False)\r\n",
    "        # save the nessecary attributes of the JSON as List\r\n",
    "        if (resp and hasattr(resp, 'results')):\r\n",
    "            for result in resp.results:\r\n",
    "                dt = datetime.datetime.fromtimestamp(result['t'] / 1000.0).isoformat()\r\n",
    "                apiResults.append([s, dt, result['o'], result['h'], result['l'], result['c']])\r\n",
    "        else: \r\n",
    "            apiResults.append([s])\r\n",
    "            print(\"[\"+datetime.datetime.now().isoformat() +\"]\" + \" - API-Call Nr. \" + str(apiCount) + \" for Stock: \" + s + \" ___no_Results___\")\r\n",
    "    apiCount+=1\r\n",
    "    print(\"[\"+datetime.datetime.now().isoformat() +\"]\" + \" - API-Call Nr. \" + str(apiCount) + \" for Stock: \" + s + \" ___success___\")\r\n",
    "    time.sleep(12)\r\n",
    "\r\n",
    "#save the List-Data as DataFrame\r\n",
    "stock_prices = pd.DataFrame(apiResults, columns=['stock', 'date', 'open', 'high', 'low', 'close'])\r\n",
    "#save the DataFrame as csv\r\n",
    "stock_prices.to_csv('../data/raw_stock_prices.csv', encoding='utf-8', index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#get the API data from the csv to DataFrame\r\n",
    "stock_prices = pd.read_csv('../data/raw_stock_prices.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Overview of the API Data\r\n",
    "\r\n",
    "Remove Stocks that has no Results from DataFrame Stock_prices and Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "stock_prices.count()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "stock_prices.sample(7)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# count NaN rows\r\n",
    "nanStocks = stock_prices[stock_prices['open'].isna() & stock_prices['close'].isna()]['stock']\r\n",
    "print(\"Total Count of Stocks with NaN: \" + str(len(nanStocks)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# remove headlines with NaN stock prices\r\n",
    "data = data.drop(data[data['stock'].isin(nanStocks)].index)\r\n",
    "\r\n",
    "# remove NaN stocks\r\n",
    "stock_prices = stock_prices.drop(stock_prices[stock_prices.open.isna() & stock_prices.close.isna()].index)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# count NaN each Column\r\n",
    "stock_prices.isnull().sum()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data.count()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "stock_prices.count()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Combine DataFrame\r\n",
    "\r\n",
    "Join on stock and date +- x"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#! Don't do this !\r\n",
    "#! No API Data for Weekends! \r\n",
    "# days before and after\r\n",
    "x = 1\r\n",
    "# add Date before\r\n",
    "data = data.assign(\r\n",
    "    date_before = lambda dataframe: dataframe['date'].map(lambda date: date.replace(date[8:10], str(int(date[8:10])+x)))\r\n",
    ")\r\n",
    "# add Date after\r\n",
    "data = data.assign(\r\n",
    "    date_after = lambda dataframe: dataframe['date'].map(lambda date: date.replace(date[8:10], str(int(date[8:10])-x)))\r\n",
    ")\r\n",
    "\r\n",
    "# JOIN\r\n",
    "headlines_with_StockPrices = pd.merge(data, stock_prices, left_on=['stock', 'date_before'], right_on=['stock', 'date'], how='left', suffixes=('', '_before'))\r\n",
    "headlines_with_StockPrices = pd.merge(headlines_with_StockPrices, stock_prices, left_on=['stock', 'date_after'], right_on=['stock', 'date'], how='left', suffixes=('', '_after'))\r\n",
    "# headlines_with_StockPrices.drop(['stock_before', 'stock_after'], 1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Format"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# format datetime to date\r\n",
    "stock_prices = stock_prices.assign(\r\n",
    "    date = lambda dataframe: dataframe['date'].map(lambda date: date[0:10])\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Understanding: Visualization after Cleaning"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Headlines Preprocessing\r\n",
    "\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Wordclouds after Data Cleaning"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Topic Modelling after Data Cleaning"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Modeling"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "e9f94fa94278d1b9bbc15332e8f5dc1ba941effd7ffdca1aa2632c253aefc311"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}